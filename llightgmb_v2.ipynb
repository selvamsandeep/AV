{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('input/test.csv', parse_dates=['ClickDate'], \n",
    "                    dtype= { 'ID' : np.int32, \n",
    "                            'Carrier' : np.float32,                             \n",
    "                             #'publisherId' : np.int32,\n",
    "                            'advertiserCampaignId' : np.float32,\n",
    "                            'Fraud': np.float32},\n",
    "                     encoding='UTF-8')  \n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_Id = test['ID'].values\n",
    "test.Country.fillna('other', inplace = True)\n",
    "test.TrafficType.fillna('other', inplace = True)\n",
    "test.Device.fillna('other', inplace = True)\n",
    "test.Browser.fillna('other', inplace = True)\n",
    "test.OS.fillna('other', inplace = True)\n",
    "test.RefererUrl.fillna('other', inplace = True)\n",
    "test.subPublisherId.fillna('other', inplace = True)\n",
    "test['publisherId'] = pd.to_numeric(test['publisherId'], errors='coerce')\n",
    "test['subPublisherId'] = pd.to_numeric(test['subPublisherId'], errors='coerce')\n",
    "\n",
    "cols_to_encode = ['Country',  'TrafficType', 'Device','Browser', 'OS', 'RefererUrl', 'UserIp', \n",
    "                 'subPublisherId','publisherId']\n",
    "le = LabelEncoder()\n",
    "for col in cols_to_encode:\n",
    "    test[col] = le.fit_transform(test[col])\n",
    "    \n",
    "test['tweekday'] = test['ClickDate'].dt.weekday\n",
    "test['thour'] = test['ClickDate'].dt.hour\n",
    "test['tminute'] = test['ClickDate'].dt.minute    \n",
    "    \n",
    "ref_url_cnt = test.groupby(['UserIp'])[ 'RefererUrl'].nunique().reset_index().\\\n",
    "                            rename(columns = {'RefererUrl': 'ref_url_cnt'})\n",
    "pubId_cnt = test.groupby(['UserIp'])[ 'publisherId'].nunique().reset_index().\\\n",
    "                        rename(columns = {'publisherId': 'pubId_cnt'})\n",
    "adv_comp_cnt = test.groupby(['UserIp'])[ 'advertiserCampaignId'].nunique().reset_index().\\\n",
    "                             rename(columns = {'advertiserCampaignId': 'compId_cnt'})\n",
    "    \n",
    "test = pd.merge(test, ref_url_cnt, how='left', on=['UserIp'])\n",
    "test = pd.merge(test, pubId_cnt, how='left', on=['UserIp'])\n",
    "test = pd.merge(test, adv_comp_cnt, how='left', on=['UserIp'])\n",
    "del ref_url_cnt, pubId_cnt, adv_comp_cnt\n",
    "\n",
    "test['refUrl_user_cnt'] = test.groupby(['RefererUrl'])['ID'].transform('count')\n",
    "test['user_cnt'] = test.groupby(['UserIp'])['ID'].transform('count')\n",
    "test['user_week_cnt'] = test.groupby(['UserIp', 'tweekday'])['ID'].transform('count')\n",
    "test['user_hr_cnt'] = test.groupby(['UserIp', 'tweekday', 'thour'])['ID'].transform('count')\n",
    "\n",
    "test['user_refurl_share'] = test['user_cnt']/ test['ref_url_cnt']\n",
    "test['user_pubid_share'] = test['user_cnt']/ test['pubId_cnt']\n",
    "test['user_compid_share'] = test['user_cnt']/test['compId_cnt']\n",
    "\n",
    "test.drop(['ID','ClickDate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25548873, 25)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "chunksize = 10 ** 7\n",
    "rows = 0\n",
    "for chunk in  pd.read_csv('input/train.csv', iterator=True, chunksize=chunksize):\n",
    "    rows += chunk.shape[0]\n",
    "    print(chunk.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "print(rows, rows//3)\n",
    "del chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chunksize = 10 ** 7\n",
    "#chunks = pd.read_csv('input/train.csv', chunksize=chunksize)\n",
    "chunks = pd.read_csv('input/train.csv', parse_dates=['ClickDate'], \n",
    "                    dtype= { 'ID' : np.int32, \n",
    "                            'Carrier' : np.float32, \n",
    "                            'ConversionPayOut' : np.float32,\n",
    "                             #'publisherId' : np.int32,\n",
    "                            'advertiserCampaignId' : np.float32,\n",
    "                            'Fraud': np.float32},\n",
    "                     encoding='UTF-8',  \n",
    "                     chunksize=chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model: 1\n",
      "[1]\tvalid_0's rmse: 6.23309\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\tvalid_0's rmse: 6.2331\n",
      "[3]\tvalid_0's rmse: 6.2331\n",
      "[4]\tvalid_0's rmse: 6.23311\n",
      "[5]\tvalid_0's rmse: 6.23308\n",
      "[6]\tvalid_0's rmse: 6.23309\n",
      "[7]\tvalid_0's rmse: 6.23311\n",
      "[8]\tvalid_0's rmse: 6.23312\n",
      "[9]\tvalid_0's rmse: 6.23315\n",
      "[10]\tvalid_0's rmse: 6.23317\n",
      "[11]\tvalid_0's rmse: 6.23312\n",
      "[12]\tvalid_0's rmse: 6.23314\n",
      "[13]\tvalid_0's rmse: 6.23318\n",
      "[14]\tvalid_0's rmse: 6.23323\n",
      "[15]\tvalid_0's rmse: 6.23326\n",
      "[16]\tvalid_0's rmse: 6.2333\n",
      "[17]\tvalid_0's rmse: 6.23334\n",
      "[18]\tvalid_0's rmse: 6.23336\n",
      "[19]\tvalid_0's rmse: 6.23332\n",
      "[20]\tvalid_0's rmse: 6.23336\n",
      "[21]\tvalid_0's rmse: 6.23338\n",
      "[22]\tvalid_0's rmse: 6.23341\n",
      "[23]\tvalid_0's rmse: 6.23345\n",
      "[24]\tvalid_0's rmse: 6.23347\n",
      "[25]\tvalid_0's rmse: 6.23352\n",
      "[26]\tvalid_0's rmse: 6.23354\n",
      "[27]\tvalid_0's rmse: 6.23356\n",
      "[28]\tvalid_0's rmse: 6.23359\n",
      "[29]\tvalid_0's rmse: 6.23361\n",
      "[30]\tvalid_0's rmse: 6.23364\n",
      "[31]\tvalid_0's rmse: 6.23365\n",
      "[32]\tvalid_0's rmse: 6.23369\n",
      "[33]\tvalid_0's rmse: 6.2337\n",
      "[34]\tvalid_0's rmse: 6.23373\n",
      "[35]\tvalid_0's rmse: 6.23376\n",
      "[36]\tvalid_0's rmse: 6.23377\n",
      "[37]\tvalid_0's rmse: 6.2338\n",
      "[38]\tvalid_0's rmse: 6.23381\n",
      "[39]\tvalid_0's rmse: 6.23381\n",
      "[40]\tvalid_0's rmse: 6.23382\n",
      "[41]\tvalid_0's rmse: 6.23384\n",
      "[42]\tvalid_0's rmse: 6.23386\n",
      "[43]\tvalid_0's rmse: 6.23389\n",
      "[44]\tvalid_0's rmse: 6.23392\n",
      "[45]\tvalid_0's rmse: 6.23395\n",
      "[46]\tvalid_0's rmse: 6.23399\n",
      "[47]\tvalid_0's rmse: 6.23404\n",
      "[48]\tvalid_0's rmse: 6.23403\n",
      "[49]\tvalid_0's rmse: 6.23404\n",
      "[50]\tvalid_0's rmse: 6.2341\n",
      "[51]\tvalid_0's rmse: 6.23412\n",
      "[52]\tvalid_0's rmse: 6.23416\n",
      "[53]\tvalid_0's rmse: 6.2342\n",
      "[54]\tvalid_0's rmse: 6.23425\n",
      "[55]\tvalid_0's rmse: 6.23428\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's rmse: 6.23308\n",
      "training model: 2\n",
      "[1]\tvalid_0's rmse: nan\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\tvalid_0's rmse: nan\n",
      "[3]\tvalid_0's rmse: nan\n",
      "[4]\tvalid_0's rmse: nan\n",
      "[5]\tvalid_0's rmse: nan\n",
      "[6]\tvalid_0's rmse: nan\n",
      "[7]\tvalid_0's rmse: nan\n",
      "[8]\tvalid_0's rmse: nan\n",
      "[9]\tvalid_0's rmse: nan\n",
      "[10]\tvalid_0's rmse: nan\n",
      "[11]\tvalid_0's rmse: nan\n",
      "[12]\tvalid_0's rmse: nan\n",
      "[13]\tvalid_0's rmse: nan\n",
      "[14]\tvalid_0's rmse: nan\n",
      "[15]\tvalid_0's rmse: nan\n",
      "[16]\tvalid_0's rmse: nan\n",
      "[17]\tvalid_0's rmse: nan\n",
      "[18]\tvalid_0's rmse: nan\n",
      "[19]\tvalid_0's rmse: nan\n",
      "[20]\tvalid_0's rmse: nan\n",
      "[21]\tvalid_0's rmse: nan\n",
      "[22]\tvalid_0's rmse: nan\n",
      "[23]\tvalid_0's rmse: nan\n",
      "[24]\tvalid_0's rmse: nan\n",
      "[25]\tvalid_0's rmse: nan\n",
      "[26]\tvalid_0's rmse: nan\n",
      "[27]\tvalid_0's rmse: nan\n",
      "[28]\tvalid_0's rmse: nan\n",
      "[29]\tvalid_0's rmse: nan\n",
      "[30]\tvalid_0's rmse: nan\n",
      "[31]\tvalid_0's rmse: nan\n",
      "[32]\tvalid_0's rmse: nan\n",
      "[33]\tvalid_0's rmse: nan\n",
      "[34]\tvalid_0's rmse: nan\n",
      "[35]\tvalid_0's rmse: nan\n",
      "[36]\tvalid_0's rmse: nan\n",
      "[37]\tvalid_0's rmse: nan\n",
      "[38]\tvalid_0's rmse: nan\n",
      "[39]\tvalid_0's rmse: nan\n",
      "[40]\tvalid_0's rmse: nan\n",
      "[41]\tvalid_0's rmse: nan\n",
      "[42]\tvalid_0's rmse: nan\n",
      "[43]\tvalid_0's rmse: nan\n",
      "[44]\tvalid_0's rmse: nan\n",
      "[45]\tvalid_0's rmse: nan\n",
      "[46]\tvalid_0's rmse: nan\n",
      "[47]\tvalid_0's rmse: nan\n",
      "[48]\tvalid_0's rmse: nan\n",
      "[49]\tvalid_0's rmse: nan\n",
      "[50]\tvalid_0's rmse: nan\n",
      "[51]\tvalid_0's rmse: nan\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-162c2311b4e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0mvalid_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlgb_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 early_stopping_rounds=50)\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0my_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gbm'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    214\u001b[0m                                         \u001b[0mbegin_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_iteration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                                         \u001b[0mend_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_iteration\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                                         evaluation_result_list=evaluation_result_list))\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mearlyStopException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mearlyStopException\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/lightgbm/callback.py\u001b[0m in \u001b[0;36mcallback\u001b[0;34m(env)\u001b[0m\n\u001b[1;32m    199\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                     print('Early stopping, best iteration is:\\n[%d]\\t%s' % (\n\u001b[0;32m--> 201\u001b[0;31m                         best_iter[i] + 1, '\\t'.join([_format_eval_result(x) for x in best_score_list[i]])))\n\u001b[0m\u001b[1;32m    202\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mEarlyStopException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_iter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_score_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "y_preds = pd.DataFrame()\n",
    "#chunksize = 10 ** 7\n",
    "chunksize = 21122405\n",
    "for train in  pd.read_csv('input/train.csv', iterator=True, chunksize=chunksize):\n",
    "    #len_train = train.shape[0]\n",
    "    y_train = train.ConversionPayOut.values\n",
    "    train.drop(['ConversionStatus','ConversionDate', 'ConversionPayOut'], inplace = True, axis=1)\n",
    "    \n",
    "    train.Country.fillna('other', inplace = True)\n",
    "    train.TrafficType.fillna('other', inplace = True)\n",
    "    train.Device.fillna('other', inplace = True)\n",
    "    train.Browser.fillna('other', inplace = True)\n",
    "    train.OS.fillna('other', inplace = True)\n",
    "    train.RefererUrl.fillna('other', inplace = True)\n",
    "    train.subPublisherId.fillna('other', inplace = True)\n",
    "    train['publisherId'] = pd.to_numeric(train['publisherId'], errors='coerce')\n",
    "    train['subPublisherId'] = pd.to_numeric(train['subPublisherId'], errors='coerce')\n",
    "    \n",
    "    cols_to_encode = ['Country',  'TrafficType', 'Device','Browser', 'OS', 'RefererUrl', 'UserIp', \n",
    "                 'subPublisherId','publisherId']\n",
    "    le = LabelEncoder()\n",
    "    for col in cols_to_encode:\n",
    "        train[col] = le.fit_transform(train[col])\n",
    "        \n",
    "    train['ClickDate'] = pd.to_datetime(train['ClickDate'])\n",
    "    train['tweekday'] = train['ClickDate'].dt.weekday\n",
    "    train['thour'] = train['ClickDate'].dt.hour\n",
    "    train['tminute'] = train['ClickDate'].dt.minute\n",
    "    \n",
    "    ref_url_cnt = train.groupby(['UserIp'])[ 'RefererUrl'].nunique().reset_index().\\\n",
    "                            rename(columns = {'RefererUrl': 'ref_url_cnt'})\n",
    "    pubId_cnt = train.groupby(['UserIp'])[ 'publisherId'].nunique().reset_index().\\\n",
    "                        rename(columns = {'publisherId': 'pubId_cnt'})\n",
    "    adv_comp_cnt = train.groupby(['UserIp'])[ 'advertiserCampaignId'].nunique().reset_index().\\\n",
    "                             rename(columns = {'advertiserCampaignId': 'compId_cnt'})\n",
    "        \n",
    "    train = pd.merge(train, ref_url_cnt, how='left', on=['UserIp'])\n",
    "    train = pd.merge(train, pubId_cnt, how='left', on=['UserIp'])\n",
    "    train = pd.merge(train, adv_comp_cnt, how='left', on=['UserIp'])    \n",
    "    del ref_url_cnt, pubId_cnt, adv_comp_cnt     \n",
    "    \n",
    "    train['refUrl_user_cnt'] = train.groupby(['RefererUrl'])['ID'].transform('count')\n",
    "    train['user_cnt'] = train.groupby(['UserIp'])['ID'].transform('count')\n",
    "    train['user_week_cnt'] = train.groupby(['UserIp', 'tweekday'])['ID'].transform('count')\n",
    "    train['user_hr_cnt'] = train.groupby(['UserIp', 'tweekday', 'thour'])['ID'].transform('count')\n",
    "    \n",
    "    train['user_refurl_share'] = train['user_cnt']/ train['ref_url_cnt']\n",
    "    train['user_pubid_share'] = train['user_cnt']/ train['pubId_cnt']\n",
    "    train['user_compid_share'] = train['user_cnt']/train['compId_cnt']\n",
    "    \n",
    "    train.drop(['ID','ClickDate'], axis=1, inplace=True)\n",
    "    \n",
    "    train_X, valid_X, train_y, valid_y = train_test_split(train, y_train, test_size=0.3, random_state=32)\n",
    "    del train, y_train\n",
    "    \n",
    "    lgb_train = lgbm.Dataset(train_X, train_y)\n",
    "    lgb_eval = lgbm.Dataset(valid_X, valid_y, reference=lgb_train)    \n",
    "    del train_X, valid_X, train_y, valid_y\n",
    "    \n",
    "    params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.02,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    #'device':'gpu',\n",
    "    'verbose': 10\n",
    "    }\n",
    "    \n",
    "    \n",
    "    print('training model: {}'.format(i))\n",
    "    gbm = lgbm.train(params,\n",
    "                lgb_train,                \n",
    "                num_boost_round=1000,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=50)\n",
    "    \n",
    "    y_preds['gbm'+ str(i)] = gbm.predict(test, num_iteration=gbm.best_iteration)\n",
    "    del lgb_train,lgb_eval    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gbm1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.024941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.024052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.023564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.023746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gbm1\n",
       "0  0.024941\n",
       "1  0.024052\n",
       "2  0.025618\n",
       "3  0.023564\n",
       "4  0.023746"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({'ID': test_Id, 'ConversionPayOut' : y_preds.gbm1.values})\n",
    "sub = sub[['ID','ConversionPayOut'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ConversionPayOut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63367289</td>\n",
       "      <td>0.024941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63367290</td>\n",
       "      <td>0.024052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63367291</td>\n",
       "      <td>0.025618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63367292</td>\n",
       "      <td>0.023564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63367293</td>\n",
       "      <td>0.023746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  ConversionPayOut\n",
       "0  63367289          0.024941\n",
       "1  63367290          0.024052\n",
       "2  63367291          0.025618\n",
       "3  63367292          0.023564\n",
       "4  63367293          0.023746"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv('lgbm_v4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
